
# Principal Component Analysis (PCA)

This repository demonstrates how to perform **Principal Component Analysis (PCA)** on a dataset, visualize the principal components, and understand the data's spread and variance directions.

## Overview

PCA is a **dimensionality reduction** technique used in machine learning and data analysis.
In this project:

* We performed PCA on a dataset.
* Visualized the **principal components**.
* Understood the **spread and variance** in data using projections.


## Dataset

* The dataset used here is a sample dataset with multiple features.
* PCA was applied after preprocessing to extract meaningful **patterns**.


## ‚öôÔ∏è Steps Performed

1. **Data Loading & Preprocessing** ‚Äì Cleaned and prepared the data.
2. **Applying PCA** ‚Äì Extracted principal components using PCA.
3. **Visualization** ‚Äì Plotted the principal components for better understanding.
4. **Interpretation** ‚Äì Analyzed directions of maximum variance in the data.


## üñºVisualization

The output includes a **2D visualization** of the first two principal components showing the data spread along maximum variance directions.



## Libraries Used

* `numpy`
* `matplotlib`
* `scikit-learn`


## Results & Insights

* PCA helped us understand the **main variance directions** in the data.
* Reduced dimensions without losing significant information.
* Useful for **visualization, noise reduction, and further ML tasks**.


## Future Scope

* Apply PCA on real-world datasets.
* Use PCA for **image compression** or **ML preprocessing**.


